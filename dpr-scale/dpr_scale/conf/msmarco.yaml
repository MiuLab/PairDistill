defaults:
  - config
  - override trainer: slurm
  - override task/optim: adamw

task:
  shared_model: false
  in_batch_eval: false
  optim:
    lr: 2.0e-5
  warmup_steps: 10000

datamodule:
  train_path: /checkpoint/xilun/datasets/dpr/msmarco/preprocessed/train.jsonl
  val_path: /checkpoint/xilun/datasets/dpr/msmarco/preprocessed/dev_small.jsonl
  test_path: /checkpoint/xilun/datasets/dpr/msmarco/preprocessed/dev_small.jsonl
  batch_size: 32
  num_negative: 0
  num_val_negative: 10
  num_test_negative: 50
  val_batch_size: 4
  test_batch_size: 1
  drop_last: false
  use_title: false

trainer:
  gpus: 8
  num_nodes: 1
  max_epochs: 40
  num_sanity_val_steps: 0
  log_every_n_steps: 10
  gradient_clip_val: 2.0
  precision: 16
  strategy: ddp_sharded
