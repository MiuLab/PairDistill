defaults:
  - config
  - override trainer: slurm

task:
  shared_model: false
  in_batch_eval: false
  optim:
    lr: 1e-4
  warmup_steps: 10000
  transform:
    max_seq_len: 512

datamodule:
  train_path: /private/home/barlaso/data/reddit/train.200M.jsonl
  val_path: /private/home/barlaso/data/reddit/dev.jsonl
  test_path: /private/home/barlaso/data/reddit/dev.jsonl
  batch_size: 32
  num_negative: 0
  num_val_negative: 0
  num_test_negative: 0
  val_batch_size: 1
  test_batch_size: 1
  drop_last: false
  use_title: true
  num_workers: 8

trainer:
  log_every_n_steps: 100
  val_check_interval: 1000
  gradient_clip_val: 2.0

hydra:
  launcher:
    comment: null
    partition: devlab,learnlab,learnfair
    timeout_min: 4320
    mem_gb: 500
    tasks_per_node: ${hydra.launcher.gpus_per_node}
    max_num_timeout: 10
